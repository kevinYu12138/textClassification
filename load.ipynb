{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3387, 3)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer,LancasterStemmer\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,classification_report\n",
    "\n",
    "# 加载数据\n",
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "remove = ('headers', 'footers', 'quotes')\n",
    "data = fetch_20newsgroups(subset='all', categories=categories, remove=remove, shuffle=True,random_state=2021)\n",
    "label2name = {i: x for i, x in enumerate(data.target_names)}\n",
    "name2label = {x: i for i, x in enumerate(data.target_names)}\n",
    "df = pd.DataFrame({'label_name':data.target, 'label':data.target, 'text':data.data})\n",
    "# print(df[:5])\n",
    "df['label_name'] = df['label_name'].map(label2name)\n",
    "# print(df[:5])\n",
    "print(df.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3387/3387 [00:00<00:00, 6288.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3387 3387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 文本清洗\n",
    "option = 'none'  # Speed: 'none'>'stem'>'lemma'\n",
    "class TextCleaner(object):\n",
    "    d1 = \"We're having a.b.c.d or i.e. u.s.a and 16.2 and U.K. and others.\"\n",
    "    d2 = \"We buy 12 apples, good apples, from Ms. ABC at 16.2 dollars/pound 24/7 from Monday-Friday. How's that?\"\n",
    "    d3 = \"1. I won't eat 1/12 of the #1 top cakes. I got 1.2 dollars or 1.2usd and a long-term/short-term goal\"\n",
    "    d4 = \"I lost 22 pounds at 9:30, 11:05 or 1:30pm or 2pm or 3pm or 1-2pm on 2016-01-02 or 01-02-2016.\"\n",
    "    d5 = \"  --He's a dedicated person. \\t He dedicated his time to work! \\n --are you sure?\"\n",
    "    d6 = \"I am interested in these interesting things that interested me.\"\n",
    "    sample_docs = [d1, d2, d3, d4, d5, d6]\n",
    "\n",
    "    def __init__(self, option='none'):\n",
    "        self.option = option\n",
    "        self.nlp = spacy.load('en_core_web_sm')\n",
    "        self.stemmer = PorterStemmer()\n",
    "\n",
    "    def lemmatize(self, text):\n",
    "        tuples = [(str(token), token.lemma_) for token in self.nlp(text)]\n",
    "        text = ' '.join([lemma if lemma != '-PRON-' else token for token, lemma in tuples])\n",
    "        text = re.sub(' ([_-]) ', '\\\\1', text)  # 'short - term' -> 'short-term'\n",
    "        return text\n",
    "\n",
    "    def text_cleanner(self, text):\n",
    "        stopwords = set(['i', 'I', 'you', 'he', 'she', 'it', 'we', 'they', 'am', 'is', 'are'])\n",
    "        text = text.lower()  # 1.lower strings\n",
    "        text = text.replace(\"'s\", 's')  # 2.handle contractions\n",
    "        text = re.sub('([a-zA-Z])\\\\.([a-zA-Z])\\\\.*', '\\\\1\\\\2', text)  # 3. handle abbreviations\n",
    "        text = re.sub('\\\\d+', '', text)  # 4. handle numbers\n",
    "        text = re.sub('[^a-zA-Z0-9\\\\s_-]', ' ', text)  # 5. remove punctuations\n",
    "        if 'lemma' in self.option:\n",
    "            text = self.lemmatize(text)  # 6. perform lemmatization\n",
    "        elif 'stem' in self.option:\n",
    "            text = ' '.join(self.stemmer.stem(x) for x in text.split(' '))  # 6. perform stemming\n",
    "        text = ' '.join(x for x in text.split(' ') if\n",
    "                        x not in stopwords)  # 7. remove stopwords(stopwords类型是set而不是list，因为set的查找速度更快)\n",
    "        text = ' '.join(x.strip('_-') for x in text.split())  # 8. remove spaces,'_' and '-'\n",
    "        return text\n",
    "\n",
    "    def transform(self, docs):  # transformer必须要有fit()和transform(）方法\n",
    "        clean_docs = []\n",
    "        self.fails = []\n",
    "        for doc in tqdm(docs):\n",
    "            try:\n",
    "                clean_docs.append(self.text_cleanner(doc))\n",
    "            except:\n",
    "                self.fails.append(doc)\n",
    "        if len(self.fails) > 0:\n",
    "            print(\"Some documents failed to be converted. Check self.fails for failed documents\")\n",
    "        return clean_docs\n",
    "\n",
    "    def fit(self, docs, y=None):\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, docs, y=None):\n",
    "        return self.fit(docs,y).transform(docs)\n",
    "\n",
    "cleaner = TextCleaner(option=option)\n",
    "# print(df['text'])\n",
    "x = cleaner.transform(df['text'])\n",
    "y = df['label'].astype('int16').to_list()\n",
    "print(len(x), len(y))\n",
    "# print(x[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: 3048 \t Y_train shape: 3048\n",
      "X_test shape: 339 \t Y_test shape: 339\n"
     ]
    }
   ],
   "source": [
    "# 划分训练集和数据集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, train_size=0.9, random_state=2021)\n",
    "print('X_train shape:', len(X_train), '\\t', 'Y_train shape:', len(Y_train))\n",
    "print('X_test shape:', len(X_test), '\\t', 'Y_test shape:', len(Y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (3048, 4000) \t Y_train shape 3048\n",
      "X_test shape: (339, 4000) \t Y_test shape 339\n"
     ]
    }
   ],
   "source": [
    "# tf-idf 创建 Document-Term Matrix\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1,2),\n",
    "    min_df=5,\n",
    "    max_df=0.95,\n",
    "    max_features=4000,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "X_train = vectorizer.fit_transform(X_train).toarray()\n",
    "X_test = vectorizer.transform(X_test).toarray()\n",
    "print('X_train shape:', X_train.shape, '\\t', 'Y_train shape', len(Y_train))\n",
    "print('X_test shape:', X_test.shape, '\\t', 'Y_test shape', len(Y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# 多分类 multi-class classification； 注意和 multi-label 的区别\n",
    "logreg = LogisticRegression(\n",
    "    penalty='l2',                # default; {'l1','l2','elasticnet','none'}\n",
    "    l1_ratio=None,               # range (0,1) used if penalty='elasticnet'\n",
    "    C=1.0,                       # default; inverse of alphs - smaller valves give stronger regularization\n",
    "    multi_class='ovr',   # default='multinomial'; {'auto','ovr','multinomial'} handles multi-class only\n",
    "    solver='liblinear',          # default; {'liblinear','lbfgs','newton-cg','sag','saga'}\n",
    "    max_iter=100,                # default;\n",
    "    tol=1e-4,                    # default; tolerance for stopping criteria\n",
    ")\n",
    "# 'ovr' fits multiple binary classifiers while 'multinomial' fits one multi-class classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(339, 4)\n",
      "(339,)\n",
      "[1 1 1 1 2]\n",
      "accuracy: 0.8201\n",
      "precision-macro: 0.8145\n",
      "precision-micro: 0.8201\n",
      "precision-weighted: 0.8231\n",
      "recall-macro: 0.7894\n",
      "recall-micro: 0.8201\n",
      "recall-weighted: 0.8201\n",
      "f1-macro: 0.7909\n",
      "f1-micro: 0.8201\n",
      "f1-weighted: 0.8121\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6842    0.7324    0.7075        71\n",
      "           1     0.9406    0.9694    0.9548        98\n",
      "           2     0.8000    0.9412    0.8649       102\n",
      "           3     0.8333    0.5147    0.6364        68\n",
      "\n",
      "    accuracy                         0.8201       339\n",
      "   macro avg     0.8145    0.7894    0.7909       339\n",
      "weighted avg     0.8231    0.8201    0.8121       339\n",
      "\n",
      "              precision  recall  f1-score   support\n",
      "0                0.6842  0.7324    0.7075   71.0000\n",
      "1                0.9406  0.9694    0.9548   98.0000\n",
      "2                0.8000  0.9412    0.8649  102.0000\n",
      "3                0.8333  0.5147    0.6364   68.0000\n",
      "accuracy         0.8201  0.8201    0.8201    0.8201\n",
      "macro avg        0.8145  0.7894    0.7909  339.0000\n",
      "weighted avg     0.8231  0.8201    0.8121  339.0000\n",
      "precision     0.8145\n",
      "recall        0.7894\n",
      "f1-score      0.7909\n",
      "support      84.7500\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "logreg.fit(X_train, Y_train)\n",
    "y_prob = logreg.predict_proba(X_test)  # 先预测概率probability\n",
    "print(y_prob.shape);y_prob[:5]   # 每行概率相加必得1\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(y_pred.shape);y_pred[:5]\n",
    "print(y_prob[:5].argmax(1))\n",
    "\n",
    "print('accuracy:',accuracy_score(Y_test,y_pred).round(4))\n",
    "print('precision-macro:',precision_score(Y_test,y_pred,average='macro').round(4))\n",
    "print('precision-micro:',precision_score(Y_test,y_pred,average='micro').round(4))\n",
    "print('precision-weighted:',precision_score(Y_test,y_pred,average='weighted').round(4))\n",
    "print('recall-macro:',recall_score(Y_test,y_pred,average='macro').round(4))\n",
    "print('recall-micro:',recall_score(Y_test,y_pred,average='micro').round(4))\n",
    "print('recall-weighted:',recall_score(Y_test,y_pred,average='weighted').round(4))\n",
    "print('f1-macro:',f1_score(Y_test,y_pred,average='macro').round(4))\n",
    "print('f1-micro:',f1_score(Y_test,y_pred,average='micro').round(4))\n",
    "print('f1-weighted:',f1_score(Y_test,y_pred,average='weighted').round(4))\n",
    "# or\n",
    "print(classification_report(Y_test,y_pred,digits=4))\n",
    "pdat = pd.DataFrame(classification_report(Y_test,y_pred,digits=4,output_dict=True)).round(4).T\n",
    "print(pdat)\n",
    "print(pdat[:4].mean(0).round(4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(339, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.03231944, 0.84011974, 0.08124227, 0.04631855],\n       [0.229273  , 0.40270175, 0.23883123, 0.12919402],\n       [0.26838048, 0.43073684, 0.09403736, 0.20684532],\n       [0.08815394, 0.67874423, 0.18136425, 0.05173758],\n       [0.29917276, 0.06455529, 0.43830047, 0.19797148]])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}